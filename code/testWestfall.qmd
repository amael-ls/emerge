---
title: "Testing the model of @Westfall2023"
date: today
author: Amaël Le Squin
date-format: iso
filters:
  - fontawesome
  - siunitx-quarto
execute:
  error: true
bibliography: references.bib
css: style.css
knitr:
  opts_chunk: 
    dev: ragg_png
    crop: null
    out.width: "70%"
    fig.width: 6
    fig.asp: 0.618
    fig.align: "center"
format:
  html:
    toc: true
    include-in-header: mathjax.html
    code-fold: true
    df-print: paged
    number-sections: true
    theme:
      light: cerulean
      dark: darkly
    margin: 5% 0;
  pdf:
    keep-tex: true
    pdf-engine: lualatex
    include-in-header:
      - text: |
          \usepackage{unicode-math}
          \usepackage{siunitx}
---

\newcommand{\ie}{\textit{i.e.,} }
\newcommand{\F}{\mathscr{F}}
\newcommand{\N}{\mathbfscr{N}}

## Introduction

The European Union \textit{i.e.,} developed a [New EU Forest Strategy for 2030](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021DC0572) as part of the plan to adapt to and fight against climate change and make Europe a climate neutral continent by 2050. This strategy relies on improved monitoring of European forests to better understand their condition and respond accordingly. Specifically, it calls for assessing carbon sequestration in forests to evaluate whether or not Europe reached carbon neutrality. One bottleneck is the harmonisation of the forest monitoring methods between European member states, if not within them. The [PathFinder project](https://pathfinder-heu.eu/#top) supports member states in implementing a European Forest Monitoring System in order to standardise or harmonise forest data collection and reporting across the EU. This prompted the Institut National de l'information Géographique et forestière (IGN), which is in charge of the French National Forest Inventory (NFI) data, to update its methods for assessing forest carbon storage.

In most countries, carbon content is estimated via two quantities: (*i*) the volume in \unit{\cubic\metre}, and (*ii*) the wood density in \unit{\kilogram\per\cubic\metre}. However, often numerous models and methods are currently used across countries, contingent upon the tree species and geographic location within each country [@Westfall2023; @Longuetaud2013; @Gregoire1996], but also the definition of tree parts [@Gschwantner2009].

## Methods

### Data
The dataset has already been prepared in `testEmerge.qmd`. First, I load the necessary packages:

```{r}
#| output: false
#### Clear space and load packages
rm(list = ls())
graphics.off()

options(max.print = 500)

library(data.table)
library(MetBrewer)
library(bayesplot)
library(cmdstanr)
	register_knitr_engine(override = TRUE)
library(stringi)
library(lognorm)
library(terra)
library(gt)

setHook(packageEvent("grDevices", "onLoad"),
function(...) grDevices::X11.options(type='cairo'))
options(device='x11')
```

The data are available on a mounted remote folder (see `testEmerge.qmd` for more details on how to mount the remote folder):

```{r}
#### Prepare data
## Loading
os = Sys.info()[['sysname']]
mnt_point = "/mnt/local_share/"
if (os == "Linux" || os == "Darwin")
{
	if (!dir.exists(mnt_point))
		stop(paste0("The mounting point <", mnt_point, "> does not exist"))
} else if (os == "Windows") {
	warning("TO DO!!! No idea how that works on Windows!")
} else {
	stop(paste("Unknown Operating System:", os))
}

path_data = paste0(mnt_point, "/data/")
if (!dir.exists(path_data))
	stop(paste0("Folder <", path_data, "> does not exist! Are you sure you mounted the good remote folder?"))

stanData = readRDS(paste0(path_data, "stanData_westfall2023.rds"))
ind_species = readRDS(paste0(path_data, "ind_species.rds"))

france = vect(inventR::france)
coords = vect(paste0(path_data, "coords"))
# coords_ifn = vect(paste0(path_data, "coords_ifn"))
france = project(france, coords)
```
Our dataset come from three sources [@Deleuze2013]:

1. the 'Protocole Oudin' (in <span class="oudin_colour"></span> on the @fig-map), which is a collection of \num{`{r} ind_species[, sum(n_indiv)]`} felled-tree destructively sampled into logs of one \unit{\metre} long (for merchantable wood, \ie trunks and branches larger than \qty{7}{\centi\metre}) and weighted branches (diameter smaller than \qty{7}{\centi\metre}) then converted into a volume. These data were collected between 1930 and 1950.

2. the French NFI (in <span class="nfi_colour"></span> on the @fig-map), which destructively sampled \num{1106099} felled-tree into two logs for the trunk and regular logs for the branches, up to a diameter of \qty{7}{\centi\metre}. Note that smaller branches were not weighted. These data were collected between the 60's and 1983.

3. the Emerge data, which gather `{r}` 


```{r}
#| label: fig-map
#| fig-cap: "Plots location of the INRA data"
#| fig-height: 8
#| fig-width: 8
#| fig-align: center
#| echo: false

plot(france, axes = FALSE, lwd = 1.5)
# points(coords_ifn, pch = 19, col = "#007BA5", cex = 0.75)
points(coords, pch = 15, col = "#FFAF37", cex = 1.25)
legend(x = "topright", legend = c("NFI", "Oudin"), pch = c(19, 15), col = c("#007BA5", "#FFAF37"), bty = "n")
```

### Model

I start building a model based on the equation of Schumacher-Hall for its parsimonious definition [@Westfall2023]:

$$
y_i = a D_i^b H_i^c,
$$ {#eq-schumacherHall}

where $y_i$ is the volume, $D_i$ is the diameter at breast height (dbh, in \unit{\metre}), and $H_i$ is the height of individual $i$. The parameters $a$, $b$, and $c$ are to be estimated. It is expected to have variation between species, and between ecodivisions [@Westfall2023], therefore the model (@eq-schumacherHall) is fitted by species, and I added a group effect on functional type (conifer or broadleaf, as in @Deleuze2014) to help rare species. I have not yet used ecodivisions. Therefore, I should add indices $j[t]$ to the parameters, to represent species $j$ in functional group $t$.

### Prepare the priors

For the priors, I use normal distributions with the average and standard deviation parameter values (see @tbl-priors) estimated in @Westfall2023, which I modified since they use cubic feet and inches (see @sec-app_convert).

```{r}
#| output: false
# The primary use of table S3a is for calculating merchantable [...] stem volumes, defined as:
# Volume from the stump height (0.9 m) upward along the trunk, stopping when the diameter is 10 cm
# This volume kind of corresponds to the "volume bois-fort tige (top diameter threshold = 7cm)"

westfall_dt = fread(paste0(path_data, "Westfall2023/Table S3a_volob_coefs_spcd.csv"))

b_prior = westfall_dt[, mean(b)]
c_prior = westfall_dt[, mean(c)]
a_prior = westfall_dt[, mean(a)]*0.3048^(3 - b_prior - c_prior)*12^b_prior # Converting 1 foot into 1 metre: 0.3048

sd_a = sd(westfall_dt[, a])*0.3048^(3 - b_prior - c_prior)*12^b_prior
```

| Parameter | Mean                    | Std. dev.                            |
|----------:|:------------------------|:-------------------------------------|
| $a$       | `{r} round(a_prior, 2)` | `{r} round(sd_a, 2)`                 |
| $b$       | `{r} round(b_prior, 2)` | `{r} round(sd(westfall_dt[, b]), 2)` |
| $c$       | `{r} round(c_prior, 2)` | `{r} round(sd(westfall_dt[, c]), 2)` |

: Prior values for the three parameters. The priors are normal distributions, with mean and standard deviation {#tbl-priors .borderless .hover}

This gives the following priors (in red):

```{r}
#| label: fig-priors
#| fig-cap: "Priors for $a$, $b$, and $c$, based on the densities from @Westfall2023"
#| fig-subcap: 
#|   - Intercept "$a$"
#|   - Power dbh "$b$"
#|   - Power height "$c$"
#| fig-height: 8
#| fig-width: 8
#| fig-align: center
#| echo: false
#| output: false
plot(density(westfall_dt[, a]), axes = FALSE, xlab = "Parameter a", lwd = 2, main = "")
curve(dnorm(x, mean = mean(westfall_dt[, a]), sd = sd(westfall_dt[, a])), add = TRUE, lwd = 2, col = "#CD212A")
axis(1)
legend(x = "topright", legend = c("Dens. params", "Prior"), fill = c("black", "#CD212A"), bty = "n")

plot(density(westfall_dt[, b]), axes = FALSE, xlab = "Parameter b", lwd = 2, main = "")
curve(dnorm(x, mean = mean(westfall_dt[, b]), sd = sd(westfall_dt[, b])), add = TRUE, lwd = 2, col = "#CD212A")
axis(1)
legend(x = "topright", legend = c("Dens. params", "Prior"), fill = c("black", "#CD212A"), bty = "n")

plot(density(westfall_dt[, c]), axes = FALSE, xlab = "Parameter c", lwd = 2, main = "")
curve(dnorm(x, mean = mean(westfall_dt[, c]), sd = sd(westfall_dt[, c])), add = TRUE, lwd = 2, col = "#CD212A")
axis(1)
legend(x = "topright", legend = c("Dens. params", "Prior"), fill = c("black", "#CD212A"), bty = "n")
```

Doing the prior predictive checks, we get:
```{r}
#| label: fig-priorPredChecks
#| fig-cap: "Prior predictive check"
#| output: false
set.seed(1969 - 08 - 18) # Woodstock seed

n_sim = 200
gen_data = vector(mode = "list", length = 20)
S = ind_species[, .N]
volume = numeric(length = length(stanData[["total_volume_m3"]]))
n_sp_broad = stanData[["n_sp_broad"]]
n_sp_conif = stanData[["n_sp_conif"]]

for (sim in seq_len(n_sim))
{
	if (sim %% 100 == 0)
		print(paste0(round(sim/n_sim*100, 2), "% done"))
	# Simulate the variances
	sigma = 1/rgamma(n = 1, shape = 2, rate = 1);
	sigma_beta0 = 1/rgamma(n = 1, shape = 3, rate = 0.5);
	sigma_beta1 = 1/rgamma(n = 1, shape = 3, rate = 0.5);
	sigma_beta2 = 1/rgamma(n = 1, shape = 3, rate = 0.5);

	# Simulate the common group 'intercepts' and dbh/height powers
	sim_a = rnorm(n = 2, mean = a_prior, sd = sd_a)
	sim_b = rnorm(n = 2, mean = b_prior, sd = sd(westfall_dt[, b]))
	sim_c = rnorm(n = 2, mean = c_prior, sd = sd(westfall_dt[, c]))

	# Simulate group-specific intercepts and slenderness slopes
	beta0 = numeric(length = S)
	beta1 = numeric(length = S)
	beta2 = numeric(length = S)
	beta0[1:n_sp_broad] = rnorm(n = n_sp_broad, mean = sim_a[1], sd = sigma_beta0);
	beta0[(n_sp_broad + 1):S] = rnorm(n = n_sp_conif, mean = sim_a[2], sd = sigma_beta0);
	beta1[1:n_sp_broad] = rnorm(n = n_sp_broad, mean = sim_b[1], sd = sigma_beta1);
	beta1[(n_sp_broad + 1):S] = rnorm(n = n_sp_conif, mean = sim_b[2], sd = sigma_beta1);
	beta2[1:n_sp_broad] = rnorm(n = n_sp_broad, mean = sim_c[1], sd = sigma_beta2);
	beta2[(n_sp_broad + 1):S] = rnorm(n = n_sp_conif, mean = sim_c[2], sd = sigma_beta2);

	# Simulate individual volume data
	# --- Broadleaves
	for (s in 1:n_sp_broad)
	{
		ind_start = ind_species[s, start]
		ind_end = ind_species[s, end]
		n_indiv = ind_species[s, n_indiv]
		
		volume[ind_start:ind_end] = rnorm(n = n_indiv,
			mean = beta0[1]*(stanData[["circumference_m"]]^beta1[1])*(stanData[["height"]]^beta2[1]), sd = sigma);
	}

	# --- Conifers
	for (s in (n_sp_broad + 1):S)
	{
		ind_start = ind_species[s, start]
		ind_end = ind_species[s, end]
		n_indiv = ind_species[s, n_indiv]
		
		volume[ind_start:ind_end] = rnorm(n = n_indiv,
			mean = beta0[2]*(stanData[["circumference_m"]]^beta1[2])*(stanData[["height"]]^beta2[2]), sd = sigma);
	}

	gen_data[[sim]] = data.table(volume = volume)
}

gen_data = rbindlist(l = gen_data, idcol = "simulation")
bounds = quantile(x = gen_data[, volume], probs = c(0.025, 0.975))
dens_gen = density(gen_data[, volume], from = bounds["2.5%"], to = bounds["97.5%"])

plot(dens_gen, axes = FALSE, lwd = 2, main = "",
	xlab = expression("Prior predicted volume in m"^3*" (from 2.5 to 97.5 percentiles)"))
abline(v = 0, lwd = 2, col = "#CD212A")
axis(1)
axis(2, las = 1)

f = approxfun(dens_gen$x, dens_gen$y)
normCst = integrate(f, min(dens_gen$x), max(dens_gen$x))$value # To force the integral to 1 on the domain
proba_negative = integrate(f, min(dens_gen$x), 0)$value/normCst


#### REMOVE AFTER, JUST FOR TEST:
estimateSumLognormal(mu = c(1, -2), sigma = c(0.25, 0.15))
aa = rlnorm(1e6, 1, 0.25) + rlnorm(1e6, -2, 0.15)
density(aa)
curve(dlnorm(x, 1.0504640, 0.2384695), lwd = 2, col = "#CD212A", add = TRUE)
```
which gives plausible results, although a probability of `{r} round(proba_negative, 2)` \unit{\percent} of being negative (which occurs when $a < 0$). Note that the density was cut at the 2.5 and 97.5 percentiles, while the minimum and maximum are `{r} round(min(gen_data), 3)` \unit{\cubic\metre} and `{r} round(max(gen_data), 3)` \unit{\cubic\metre}, respectively.

### Stan model

::: callout-tip
## Stan engine

By default, Quarto uses the knitr's built-in stan engine `rstan`. To override it so that all stan chunks are processed with `CmdStanR`, I need to specify:

```{r}
#| eval: false
#| code-fold: false
register_knitr_engine(override = TRUE)
```
:::

```{stan output.var = "stan_westfall", cache = TRUE}
data {
	// Dimensions and indices
	int N; // Number of individuals
	int S; // Number of species
	int<lower = 0, upper = S> n_sp_broad; // number of broadleaf species
	int<lower = S - n_sp_broad, upper = S - n_sp_broad> n_sp_conif; // number of conifer species
	array[n_sp_broad] int ind_start_broad; // Broadleaf species index start
	array[n_sp_conif] int ind_start_conif; // Conifer species index start
	array[n_sp_broad] int ind_end_broad; // Broadleaf species index end
	array[n_sp_conif] int ind_end_conif; // Conifer species index end

	// Predictors
	vector<lower = 0> [N] height;
	vector<lower = 0> [N] circumference_m;

	// Response variable
	vector [N] total_volume_m3;
}

parameters {
	// Fixed effects (population parameters) for broadleaf and conifer
	vector[2] a;
	vector[2] b;
	vector[2] c;
	
	// Random effects (group parameters)
	vector[S] beta0;
	vector[S] beta1;
	vector[S] beta2;

	// Variances
	real<lower = 0> sigma; // sd residuals
	real<lower = 0> sigma_beta0; // sd random effect beta0
	real<lower = 0> sigma_beta1; // sd random effect beta1
	real<lower = 0> sigma_beta2; // sd random effect beta2
}

model {
	// Priors
	// --- Population parameters
	target += normal_lpdf(a | 0.36, 0.16);
	target += normal_lpdf(b | 1.87, 0.10);
	target += normal_lpdf(c | 0.98, 0.12);

	// --- Residual variance and population variance
	target += inv_gamma_lpdf(sigma | 2, 1); // Uses shape and scale (which is the rate from gamma perspective)
	target += inv_gamma_lpdf(sigma_beta0 | 3, 0.5); // Uses shape and scale (which is the rate from gamma perspective)
	target += inv_gamma_lpdf(sigma_beta1 | 3, 0.5); // Uses shape and scale (which is the rate from gamma perspective)
	target += inv_gamma_lpdf(sigma_beta2 | 3, 0.5); // Uses shape and scale (which is the rate from gamma perspective)

	// Hierarchy
	target += normal_lpdf(beta0[1:n_sp_broad] | a[1], sigma_beta0);
	target += normal_lpdf(beta1[1:n_sp_broad] | b[1], sigma_beta0);
	target += normal_lpdf(beta2[1:n_sp_broad] | c[1], sigma_beta2);
	target += normal_lpdf(beta0[(n_sp_broad + 1):S] | a[2], sigma_beta0);
	target += normal_lpdf(beta1[(n_sp_broad + 1):S] | b[2], sigma_beta0);
	target += normal_lpdf(beta2[(n_sp_broad + 1):S] | c[2], sigma_beta2);

	// Likelihood broadleaves, i = species
	for (i in 1:n_sp_broad)
	{
		target += normal_lpdf(total_volume_m3[ind_start_broad[i]:ind_end_broad[i]] | beta0[i] *
			circumference_m[ind_start_broad[i]:ind_end_broad[i]]^beta1[i] .*
			height[ind_start_broad[i]:ind_end_broad[i]]^beta2[i],
			sigma);
	}

	// Likelihood conifers, i = species
	for (i in 1:n_sp_conif)
	{
		target += normal_lpdf(total_volume_m3[ind_start_conif[i]:ind_end_conif[i]] | beta0[n_sp_broad + i] +
			circumference_m[ind_start_conif[i]:ind_end_conif[i]]^beta1[n_sp_broad + i] .*
			height[ind_start_conif[i]:ind_end_conif[i]]^beta2[n_sp_broad + i],
			sigma);
	}
}

```

### Run the model
In total, there are `{r} 3*(S + 2 + 1) + 1 + 1` parameters to estimate.
```{r}
n_chains = 4
iter_warmup = 750
iter_sampling = 1250

stan_westfall = cmdstan_model(stan_file = "toto.stan")

## Fit
if (!file.exists("fit_westfall.rds"))
{
	fit = stan_westfall$sample(data = stanData, chains = n_chains, parallel_chains = ifelse(n_chains < 4, n_chains, 4),
			seed = NULL, refresh = 200, max_treedepth = 12, save_warmup = TRUE,
			iter_sampling = iter_sampling, iter_warmup = iter_warmup, adapt_delta = 0.95)
	fit$save_output_files(dir = "./", basename = paste0("fit_westfall"), random = FALSE)
	saveRDS(fit, "./fit_westfall.rds")
} else {
	fit = readRDS("./fit_westfall.rds")
}

mcmc_rhat(rhat(fit))
mcmc_neff(neff_ratio(fit))
mcmc_nuts_divergence(nuts_params(fit), lp = log_posterior(fit))
```

It seems that there is no convergence problem in the model of @Westfall2023 with the INRA data

## Feet and inches to metres {#sec-app_convert .apendix}

Of course, @Westfall2023 had to provide their parameter values in inches and feet rather than in the international system... Here is an example that shows how to convert into metres:

```{r}
alpha = 0.3048 # Converting 1 foot into 1 metre

a = 2.3
b = 0.5
c = 0.02

n = 50

D = runif(n = n, min = 1, max = 55) # In inch
H = runif(n = n, min = 6, max = 150) # In foot
y = a*D^b*H^c

y_m3 = alpha^3*y # In metre

D_m = alpha/12*D # In metre
H_m = alpha*H # In metre

all.equal(a*alpha^(3 - b - c)*12^b*D_m^b*H_m^c, y_m3)  # Should be TRUE
```