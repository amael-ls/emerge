---
title: "Notes on @Parresol2001"
date: today
author: Amaël Le Squin
date-format: iso
pdf-engine: lualatex
keep-tex: true
execute:
  error: true
  echo: false
  warning: false
  message: false
bibliography: ./centralised_bibliography/references.bib
lightbox:
  match: auto
css: style.css
knitr:
  opts_chunk: 
    dev: ragg_png
    crop: null
    out.width: "70%"
    fig.width: 6
    fig.asp: 0.618
    fig.align: "center"
format:
  html:
    toc: true
    include-in-header: mathjax.html
    code-fold: true
    df-print: paged
    number-sections: true
    theme:
      light: cerulean
      dark: darkly
    margin: 5% 0;
---

```{r}
#| output: false

#### Clear space and load packages
# rm(list = ls())
graphics.off()

options(max.print = 500)

library(data.table)
library(MetBrewer)
library(cmdstanr)
	register_knitr_engine(override = TRUE)
library(stringi)
library(DHARMa)
library(gt)

## Tool function
source("./toolFunctions.R")
```

## Introduction

This is a summary of @Parresol2001 to test and understand the Nonlinear Seemingly Unrelated Rgression (NSUR). I first apply his 'naive' model, and then apply an NSUR model. The data are available in his paper, that I copied into a data table in R.

## Data
```{r}
#| output: false

data = data.table(
	id = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
		21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40),
	dbh = c(5.6, 6.4, 8.1, 8.4, 9.1, 9.9, 10.4, 11.2, 11.7, 12.2, 11.9, 13.2, 12.2, 13.7,
		14.2, 15.0, 15.7, 16.5, 16.5, 19.6, 17.5, 17.8, 18.5, 19.6, 18.5, 19.8, 20.6, 21.6, 19.8,
		22.9, 23.6, 23.1, 24.1, 26.4, 24.6, 25.1, 29.0, 28.4, 31.8, 33.0),
	height = c(7.9, 8.5, 10.7, 11.3, 11.0, 13.1, 14.3, 14.6, 14.3, 14.9, 16.8, 13.7, 15.8, 18.0,
		16.5, 20.1, 16.8, 17.1, 17.1, 13.7, 19.2, 18.3, 17.7, 19.8, 22.9, 18.6, 17.4, 17.7, 18.9,
		19.8, 18.3, 18.9, 21.3, 19.2, 25.0, 19.8, 20.4, 26.8, 27.4, 27.7),
	crown_length = c(2.1, 1.2, 2.7, 3.4, 4.3, 3.4, 5.5, 4.0, 4.0, 6.1, 4.6, 4.6, 5.5, 2.4,
		6.4, 3.0, 4.9, 4.9, 4.0, 6.7, 7.6, 6.4, 6.4, 7.6, 4.0, 6.7, 5.8, 8.2, 7.3, 8.5, 7.9,
		7.9, 9.4, 7.3, 5.8, 8.5, 8.5, 7.3, 8.2, 10.4),
	age = c(21, 21, 20, 21, 21, 21, 32, 19, 21, 21, 32, 20, 19, 32, 19, 32, 21, 20, 21,
		16, 19, 21, 21, 19, 32, 21, 21, 20, 19, 19, 20, 21, 21, 19, 32, 21, 20, 32, 32, 45),
	wood = c(6.5, 7.4, 17.6, 18.5, 22.6, 30.6, 32.9, 40.6, 46.0, 51.6, 60.4, 62.8, 67.5, 81.2,
		94.3, 123.4, 107.3, 123.8, 151.6, 140.4, 170.4, 169.6, 160.3, 199.8, 231.6, 217.9, 216.0,
		200.6, 217.5, 314.8, 287.1, 290.9, 320.1, 308.6, 403.0, 390.4, 445.2, 736.4, 770.9, 921.3),
	bark = c(2.3, 2.6, 4.5, 4.3, 5.4, 7.4, 6.7, 9.3, 10.7, 13.1, 10.1, 15.2, 12.9, 12.5, 18.2,
		16.5, 21.5, 22.1, 24.6, 25.1, 27.4, 31.7, 36.9, 38.7, 29.6, 33.9, 32.6, 40.2, 38.5, 43.1,
		63.4, 44.3, 50.6, 65.7, 49.8, 48.8, 60.4, 84.0, 93.8, 108.0),
	crown = c(1.0, 2.1, 2.3, 4.2, 5.6, 5.5, 6.4, 6.2, 7.7, 6.1, 5.4, 10.7, 15.3, 8.7, 11.2,
		7.7, 19.7, 28.9, 16.8, 46.2, 16.8, 24.0, 47.5, 19.7, 24.6, 45.8, 61.2, 75.4, 62.0,
		43.2, 51.7, 76.7, 75.6, 116.0, 69.8, 83.5, 88.0, 79.9, 170.2, 169.2),
	tree = c(9.8, 12.1, 24.4, 27.0, 33.6, 43.5, 46.0, 56.1, 64.4, 70.8, 75.9, 88.7, 95.7,
		102.4, 123.7, 147.6, 148.5, 174.8, 193.0, 211.7, 214.6, 225.3, 244.7, 258.2, 285.8,
		297.6, 309.8, 316.2, 318.0, 401.1, 402.2, 411.9, 446.3, 490.3, 522.6, 522.7, 593.6,
		900.3, 1034.9, 1198.5)
)

data[, all.equal(tree, wood + bark + crown)]
```

::: {.callout-note collapse="true"}

## Data of *Pinus elliottii*

Data used in @Parresol2001, with the smallest and largest tree (in terms of dbh) highlighted (used to plot posteriors of the variance in the model considering heteroskedasticity).
```{r}
data[, .(dbh, height, wood)] |>
	gt() |>
	cols_label(
		dbh = "Diameter",
		height = "Height",
		wood = "Trunk biomass"
	) |>
	tab_style(
		style = cell_borders(sides = "all", style = NULL),
		locations = cells_body()
	) |>
	tab_style(
		style = cell_text(weight = "bold", align = "right"),
		locations = list(cells_column_labels(), cells_column_spanners())
	) |>
	data_color(
		columns = everything(),
		rows = (dbh == min(dbh)) | (dbh == max(dbh)),
		direction = "column",
		palette = c("#FAB255", "#0F7BA2")
)
```

:::

## Model 1, equation 15

### Heteroskedasticity ignored

The basic model is:

$$
\begin{aligned}
\text{wood} &\sim N \Big(b_{1, 1} (d^2 h)^{b_2, 1}, \, \sigma_1 \Big) \\
\text{bark} &\sim N \Big(b_{1, 2} d^{b_{2, 2}}, \, \sigma_2 \Big) \\
\text{crown} &\sim N \Big(b_{1, 3} d^{b_{2, 3}} h^{b_3}, \, \sigma_3 \Big)
\end{aligned}
$$

which is the equation 15 in @Parresol2001, with a clarification on the parameters (he only uses $b_1$, $b_2$, and $b_3$ despite the $b_1$ of wood is not the same as $b_1$ bark). In this version, the heteroskedasticity is ignored.

```{stan output.var = "eq15", cache = TRUE}
data {
	// Dimensions
	int<lower = 1> N; // Number of data

	// Explanatory variables
	vector[N] diameter;
	vector[N] height;

	// Observations
	vector[N] wood;
	vector[N] bark;
	vector[N] crown;
}

parameters {
	// Regression parameters (intercept and power)
	array[3] real <lower = 0> b1; // Intercepts for each tree component
	array[3] real b2; // Powers for each tree component
	real b3; // Power

	// Std. dev.
	array[3] real <lower = 0> sigma;
}

model {
	target += gamma_lpdf(b1 | 1, 1); // 0.05^2/0.002, 0.05/0.002);
	target += normal_lpdf(b2 | 0, 1);
	target += normal_lpdf(b3 | 0, 1);

	target += gamma_lpdf(sigma | 0.001, 0.001);

	target += normal_lpdf(wood | b1[1] * (diameter.^2 .* height).^b2[1], sigma[1]);
	target += normal_lpdf(bark | b1[2] * diameter.^b2[2], sigma[2]);
	target += normal_lpdf(crown | b1[3] * diameter.^b2[3] .* height.^b3, sigma[3]);
}

generated quantities {
	// Simulations (for wood only)
	array [N] real wood_sim = normal_rng(b1[1] * (diameter.^2 .* height).^b2[1], sigma[1]);
	vector [N] mean_pred = b1[1] * (diameter.^2 .* height).^b2[1];
}
```

```{r}
#| output: false

## Run stan model
# Data
stanData = list(
	N = data[, .N],

	diameter = data[, dbh],
	height = data[, height],
	
	wood = data[, wood],
	bark = data[, bark],
	crown = data[, crown]
)

# Parameters
n_chains = 4

# Running
results = eq15$sample(data = stanData, chains = n_chains, parallel_chains = n_chains)

## Residuals
n_sampling = results$metadata()$iter_sampling

simResp = results$draws("wood_sim")
dim(simResp)

# Reshape simResp as a matrix nobs x n_repetition
simResp_matrix = matrix(data = 0, nrow = data[, .N], ncol = n_sampling*n_chains)
for (obs in seq_len(data[, .N]))
{
	col_start = 1
	for (chain in 1:n_chains)
	{
		col_end = chain*n_sampling
		simResp_matrix[obs, col_start:col_end] = simResp[, chain, obs]
		col_start = col_end + 1
	}
}

## Simulated residuals
sim_dharma = createDHARMa(simulatedResponse = simResp_matrix,
	observedResponse = data[, wood],
	fittedPredictedResponse = apply(results$draws("mean_pred"), MARGIN = 3, median),
	integerResponse = FALSE)
```

As expected, heteroskedasticity is clearly visible on the residuals (@fig-residuals_simple), with an increase of variance with diameter and height (combined here as a 'cylinder volume'---although cm mixed with metres).
```{r}
#| label: fig-residuals_simple
#| fig-cap: "Model check"
#| fig-sucap:
#|   - "Residuals of the 'naive' model"
#|   - "Predictions"
#| fig-asp: 1
#| out-width: 95%
#| fig-width: 4
#| layout-ncol: 2

plotResiduals(sim_dharma, data[, dbh^2*height], quantreg = TRUE, xlab = "D²h", main = "")

## Prediction of trunk volume
# Median volume predictions
b1 = median(results$draws("b1[1]"))
b2 = median(results$draws("b2[1]"))

wood_sim = apply(X = results$draws("wood_sim"), MARGIN = 3, FUN = median)

f = function(x, a, b)
	return(a*x^b)

## Credibility intervals for the smallest and largest tree
smallest_cred = quantile(results$draws("wood_sim[1]"), c(0.05, 0.5, 0.95))
largest_cred = quantile(results$draws("wood_sim[40]"), c(0.05, 0.5, 0.95))

## Plot
plot(data[, dbh^2*height], wood_sim, pch = 19, axes = FALSE, xlab = "D²h", ylab = "Wood biomass",
	col = "#0F7BA2", ylim = c(0, max(data[, wood], wood_sim, largest_cred)))
points(data[, dbh^2*height], data[, wood], pch = 15, col = "#FAB255", cex = 0.75)
curve(f(x, b1, b2), lwd = 2, col = "#CD212A", add = TRUE)
axis(1)
axis(2, las = 1)
segments(x0 = data[1, dbh^2*height], y0 = smallest_cred["5%"], y1 = smallest_cred["95%"])
segments(x0 = data[40, dbh^2*height], y0 = largest_cred["5%"], y1 = largest_cred["95%"])
```

### Heteroskedasticity considered
In this section, I consider heteroskedasticity, using the following equations (taken from the weight in Tab. 2, @Parresol2001), the other equations remaining the same:

$$
\begin{aligned}
\sigma_{\text{wood}} &= \sigma_1 (D^2 h)^{c_1} \\
\sigma_{\text{bark}} &= \sigma_2 D^{c_2} \\
\sigma_{\text{crown}} &= \sigma_3 D^{c_{3, 1}} \exp[c_{3, 2} h^2]
\end{aligned}
$$

```{stan output.var = "eq15_heterosked", cache = TRUE}
data {
	// Dimensions
	int<lower = 1> N; // Number of data

	// Explanatory variables
	vector[N] diameter;
	vector[N] height;

	// Observations
	vector[N] wood;
	vector[N] bark;
	vector[N] crown;
}

parameters {
	// Regression parameters (intercept and power)
	array[3] real <lower = 0> b1; // Intercepts for each tree component
	array[3] real b2; // Powers for each tree component
	real b3; // Power
	
	// Variance parameters
	real c1;
	real c2;
	array[2] real c3;

	// Std. dev.
	array[3] real <lower = 0> sigma;
}

model {
	target += gamma_lpdf(b1 | 1, 1); // 0.05^2/0.002, 0.05/0.002);
	target += normal_lpdf(b2 | 0, 1);
	target += normal_lpdf(b3 | 0, 1);

	target += normal_lpdf(c1 | 0, 1);
	target += normal_lpdf(c2 | 0, 1);
	target += normal_lpdf(c3 | 0, 1);

	target += gamma_lpdf(sigma | 0.001, 0.001);

	target += normal_lpdf(wood | b1[1] * (diameter.^2 .* height).^b2[1],
		sigma[1] * (diameter.^2 .* height).^c1);
	target += normal_lpdf(bark | b1[2] * diameter.^b2[2],
		sigma[2] * diameter .^ c2);
	target += normal_lpdf(crown | b1[3] * diameter.^b2[3] .* height.^b3,
		sigma[3] * diameter .^ c3[1] .* exp(c3[2] * height.^2));
}

generated quantities {
	// Simulations (for wood only)
	array [N] real wood_sim = normal_rng(b1[1] * (diameter.^2 .* height).^b2[1],
		sigma[1] * (diameter.^2 .* height).^c1);
	vector [N] mean_pred = b1[1] * (diameter.^2 .* height).^b2[1];
	vector [N] var_pred = sigma[1] * (diameter.^2 .* height).^c1;
}
```

```{r}
#| output: false

## Run stan model
# Running
results_heterosked = eq15_heterosked$sample(data = stanData, chains = n_chains, parallel_chains = n_chains,
	max_treedepth = 12, iter_warmup = 1750, iter_sampling = 1500)

## Check results
apply(X = results_heterosked$draws("b1"), MARGIN = 3, FUN = mean)
apply(X = results$draws("b1"), MARGIN = 3, FUN = mean)

apply(X = results_heterosked$draws("b2"), MARGIN = 3, FUN = mean)
apply(X = results$draws("b2"), MARGIN = 3, FUN = mean)

mean(results_heterosked$draws("b3"))
mean(results$draws("b3"))
```

```{r}
#| label: fig-posterior
#| fig-cap: Few cheks of posteriors and predictions
#| fig-subcap:
#|   - "Posterior variance smallest tree"
#|   - "Posterior variance largest tree"
#|   - "Prediction of variance"
#|   - "Prediction of trunk volume"
#| fig-asp: 1
#| out-width: 95%
#| fig-width: 4
#| layout-ncol: 2
#| output: false

#### Few plots
## Posteriors of predicted variance for tree 1 (smallest)  and 40 (largest)
aa = lazyPosterior(results_heterosked$draws("var_pred[1]"))
bb = lazyPosterior(results_heterosked$draws("var_pred[40]"))

## Fit of the variance (median computed, mean is off due to fat-tailed posterior sigma1)
y = apply(X = results_heterosked$draws("var_pred"), MARGIN = 3, FUN = median)
sigma1 = median(results_heterosked$draws("sigma[1]"))
c1 = median(results_heterosked$draws("c1"))

plot(data[, dbh^2*height], y, pch = 19, axes = FALSE, xlab = "D²h", ylab = "Variance")
curve(f(x, sigma1, c1), lwd = 2, col = "#CD212A", add = TRUE)
axis(1)
axis(2, las = 1)

## Prediction of trunk volume
# Median volume predictions
b1 = median(results_heterosked$draws("b1[1]"))
b2 = median(results_heterosked$draws("b2[1]"))

wood_sim = apply(X = results_heterosked$draws("wood_sim"), MARGIN = 3, FUN = median)

## Credibility intervals for the smallest and largest tree
smallest_cred = quantile(results_heterosked$draws("wood_sim[1]"), c(0.05, 0.5, 0.95))
largest_cred = quantile(results_heterosked$draws("wood_sim[40]"), c(0.05, 0.5, 0.95))

## Plot
plot(data[, dbh^2*height], wood_sim, pch = 19, axes = FALSE, xlab = "D²h", ylab = "Wood biomass",
	col = "#0F7BA2", ylim = c(0, max(data[, wood], wood_sim, largest_cred)))
points(data[, dbh^2*height], data[, wood], pch = 15, col = "#FAB255", cex = 0.75)
curve(f(x, b1, b2), lwd = 2, col = "#CD212A", add = TRUE)
axis(1)
axis(2, las = 1)
segments(x0 = data[1, dbh^2*height], y0 = smallest_cred["5%"], y1 = smallest_cred["95%"])
segments(x0 = data[40, dbh^2*height], y0 = largest_cred["5%"], y1 = largest_cred["95%"])
```

```{r}
## Residuals
n_sampling_heterosked = results_heterosked$metadata()$iter_sampling

simResp = results_heterosked$draws("wood_sim")
dim(simResp)

# Reshape simResp as a matrix nobs x n_repetition
simResp_matrix = matrix(data = 0, nrow = data[, .N], ncol = n_sampling_heterosked*n_chains)
for (obs in seq_len(data[, .N]))
{
	col_start = 1
	for (chain in 1:n_chains)
	{
		col_end = chain*n_sampling_heterosked
		simResp_matrix[obs, col_start:col_end] = simResp[, chain, obs]
		col_start = col_end + 1
	}
}

## Simulated residuals
sim_dharma = createDHARMa(simulatedResponse = simResp_matrix,
	observedResponse = data[, wood],
	fittedPredictedResponse = apply(results_heterosked$draws("mean_pred"), MARGIN = 3, median),
	integerResponse = FALSE)
```

As can be seen, the residuals are good when heteroskedasticity is considered (see @fig-residuals_heterosked).
```{r}
#| label: fig-residuals_heterosked
#| fig-cap: Residuals of the model accounting for heteroskedasticity
#| fig-asp: 1
#| out-width: 95%
#| fig-width: 6

plotResiduals(sim_dharma, data[, dbh^2*height], quantreg = TRUE)
```



## Bibliography {.unnumbered}

::: {#refs}
:::
