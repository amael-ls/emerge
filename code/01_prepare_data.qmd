---
title: "Preparing the data for estimating volumes"
date: today
author: Amaël Le Squin
date-format: iso
filters:
  - fontawesome
execute:
  error: true
bibliography: references.bib
css: style.css
knitr:
  opts_chunk: 
    dev: ragg_png
    crop: null
    out.width: "70%"
    fig.width: 6
    fig.asp: 0.618
    fig.align: "center"
format:
  html:
    toc: true
    include-in-header: mathjax.html
    code-fold: true
    df-print: paged
    number-sections: true
    theme:
      light: cerulean
      dark: darkly
    margin: 5% 0;
  pdf:
    keep-tex: true
    pdf-engine: lualatex
    include-in-header:
      - text: |
          \usepackage{unicode-math}
---

\newcommand{\ie}{*i.e.,*}
\newcommand{\F}{\mathscr{F}}
\newcommand{\N}{\mathbfscr{N}}

## Introduction

The data were provided by Christine Deleuze by e-mail the 17 September 2024. The format is a single `.RData` file, which is stored remotely on the server 'Abies' (`smb://del1509n015/`) in the protected folder (only reading rights) `2024_faircarbon/data_orig/`. The person to contact to add data to this folder is Thierry Leclaire.

For Linux, and maybe MacOS, it is necessary to mount locally the remote folder in order to access the data from R. According to Henri Cunny, it is not necessary for Windows (at least for remote folders on Abies, maybe because smb is a Windows protocol).

### Mount the remote folder

1.  Switch to super user where you replace `JohnField-Admin` (really nice [Irish composer](https://www.youtube.com/watch?v=Uktj2MYSsaU)) by your admin name (typically, your IGN id followed by `-Admin`):

```{sh}
#| eval: false
#| code-fold: false
su JohnField-Admin
```

Your **admin** password will be asked

2.  Create a directory where you will mount the remote folder. By default I like to put it in `/mnt/local_share`. You need to be super user to write in `/mnt/`:

```{sh}
#| eval: false
#| code-fold: false
sudo mkdir /mnt/local_share
```

This step should be done only once.

3.  Mount the remote folder `smb://del1509n015/2024_faircarbon/`, where you replace `your_name` by your **usual** IGN id (NOT the admin one):

```{sh}
#| eval: false
#| code-fold: false
sudo mount -t cifs -o username=your_name,domain=ign,uid=your_name //del1509n015/2024_faircarbon /mnt/local_share/
```

Maybe two passwords will be asked, first your **admin** password to execute the `sudo`, and then your **usual** password. If you just did step 2, then the prompt will not ask again for your **admin** password again.

4.  Check that it worked, especially the reading and writting rigths:

```{sh}
#| eval: false
#| code-fold: false
ls -l /mnt/local_share/
```

The content of the remote folder should appear. You can close your admin session by using `ctrl + d` or `Cmd + d`

Now that the raw data are accessible to {{< fa brands r-project >}}, it is time to prepare them!

## Prepare the data

### Loading the data

The following packages are required to load and handle the data and print summary tables

```{r}
#| output: false
#### Clear space and load packages
rm(list = ls())
graphics.off()

options(max.print = 500)

library(data.table)
library(inventR)
library(stringi)
library(gt)
```

And one helper function to convert degree coordinates to decimals (for the INRA data):

```{r}
angle2dec = function(angle)
{
	x = stri_match(angle, regex = "([+-]?\\d+)°(\\d+)'(\\d+)") # To split the degree from minute and second
	x = apply(x[, 2:4], 1L, function(y) {
		y = as.numeric(y)
		y[1] + y[2]/60 + y[3]/3600
	})
	return(x)
}
```

Read the data from (mounted) remote folder:
```{r}
#### Prepare data
## Loading
os = Sys.info()[['sysname']]
mnt_point = "/mnt/local_share/"
if (os == "Linux" || os == "Darwin")
{
	if (!dir.exists(mnt_point))
		stop(paste0("The mounting point <", mnt_point, "> does not exist"))
} else if (os == "Windows") {
	stop("TO DO!!! No idea how that works on Windows!")
} else {
	stop(paste("Unknown Operating System:", os))
}

path_data = paste0(mnt_point, "/data_orig/")
if (!dir.exists(path_data))
	stop(paste0("Folder <", path_data, "> does not exist! Are you sure you mounted the good remote folder?"))

if (list.files(path = path_data) != "EMERGE.RData")
	stop("There should be only the file <EMERGE.RData> in the data_orig folder")

load(paste0(path_data, "EMERGE.RData"))
```

There are data from different institutes and different periods of time:

1.  'Protocole Oudin', dataset preserved by INRA ( on the @fig-map)

2.  The French NFI ( on the @fig-map). I do not trust this dataset: I do not know where it comes from, nor who provided it, but there are about 50% of the plot id (labelled `CPP` in the table) that cannot be found when I or Cedric Duprez do our own request. Therefore, I decided to do my own request of the data, which is also better for reproducibility. Details are explained in @sec-nfi_query

3.  The 'Office National des Forêts (ONF)', with protocols from 1972 and from 1983. I do not use these data as there is no coordinates

4.  Institut Technologique Forêt, Cellulose, Bois-construction, Ameublement (FCBA), which I do not use so far

5.  L'Institut pour le développement forestier (IDF) which is the R&D of the Centre National de la Propriété Forestière and the Institut national de recherche en sciences et technologies pour l'environnement et l'agriculture (IRSTEA, currently INRAE)

### Variable names

The variable names are not necessarily unified (but the species names are, I checked! So I can safely use the data.table `codesessences`). I gather in @tbl-notations the data-specific variable names and the common english name I use hereafter.

| INRA            | NFI  | Common                       | Description                                     |
|----------------:|-----:|:-----------------------------|:------------------------------------------------|
| id              | npp  | plot_id                      | Plot id                                         |
| nom_fichier     | \-   | unique_id                    | Unique id                                       |
| essence         | ess  | speciesName_sci              | Species name                                    |
| c130            | c13  | circumference_m              | Circumference at 1.3 m                          |
| h_tot           | htot | height                       | Height in m                                     |
| total_volume_m3 | \-   | total_volume_m3              | Total above-ground volume                       |
| v_tronc         | v    | merchantable_trunk_volume_m3 | Volume main trunk up to 7 cm                    |
| v_menu          | \-   | small_branch_volume_m3       | Volume of branches with diameter lower than 7cm |
| genre           | \-   | genus                        | Genus                                           |
| longitude       | xl   | \-                           | Coordinates in different proj                   |
| latitude        | yl   | \-                           | Coordinates in different proj                   |

: Variable names {#tbl-notations}

### Clean the datasets and compute new variables

Keep only the columns of interest, change column names, transform everything to `data.table` for INRA data and for helper data tables (`codesforets`, which contains coordinates, and `codesessences`, which contains species codes):
```{r}
setDT(inra_arbres)
setDT(codesforets)
setDT(codesessences)

## Compute (total) volume in m³, circumference in m, hardiness, and slenderness
inra_arbres[, total_volume_m3 := (v_tronc_verif + v_fourche_verif + v_fourche2_verif + v_br_verif + v_menu_verif)/1e3]
inra_arbres[, v_tronc_verif := v_tronc_verif/1e3] # Conversion to m3
inra_arbres[, v_menu_verif := v_menu_verif/1e3] # Conversion to m3
inra_arbres[, circumference_m := c130/100]
inra_arbres[, hdn := sqrt(circumference_m)/h_tot]
inra_arbres[, slenderness := h_tot/circumference_m]

## Keep only column of interest and rename them
inra_arbres = unique(inra_arbres[, .(nom_fichier, essence, circumference_m, h_tot, total_volume_m3, v_tronc_verif,
	v_menu_verif, genre, id_codesforets)])
inra_arbres = merge.data.table(inra_arbres, codesforets[, .(id, longitude, latitude)],
	by.x = "id_codesforets", by.y = "id")
inra_arbres = na.omit(inra_arbres)

setnames(inra_arbres, new = c("plot_id", "unique_id", "speciesName_sci", "circumference_m", "height", "total_volume_m3",
	"merchantable_trunk_volume_m3", "small_branch_volume_m3", "genus", "lon", "lat"))

## Change type of cols
inra_arbres[, unique_id := as.character(unique_id)]
inra_arbres[, speciesName_sci := as.character(speciesName_sci)]
inra_arbres[, genus := as.character(genus)]

## Set functional type, either broadleaf or conifer
inra_arbres[, fct_type := "broadleaf"]
inra_arbres[genus %in% c("Abies", "Cedrus", "Larix", "Picea", "Pinus", "Pseudotsuga", "Thuya", "Tsuga"),
	fct_type := "conifer"]

## Number of individuals per species
inra_arbres[, nb_indiv := .N, by = speciesName_sci]
# inra_arbres = inra_arbres[nb_indiv > 20]
```

### Request of the French NFI data (using inventR package) {#sec-nfi_query}

As said above, I do not trust the data.frame `ifn_arbres`. I do my own request here, to get tree volumes and the plot coordinates. Note that I filtered trees measured before 1988 because diameters were collected instead of circumferences. This is known to be less precise (as the trunk is more likely to be an ovoid) and so it is better to start from 1988, where the circumferences are measured (Florence Gohon, *pers. comm.*).

```{r}
## French NFI data
db = connect_db()

nfi_data = exec_req(conn = db, req = "
	SELECT
		tree.NPP, tree.A, tree.ESS, tree.C13, tree.HTOT, tree.R, tree.V, tree.VTOT,
		coords1.XL, coords1.YL
	FROM
		inv_exp_am.g3arbre AS tree
		
		LEFT JOIN inv_exp_am.e1point AS coords1
		ON coords1.npp = tree.npp
		
		LEFT JOIN inv_exp_am.e2point AS coords2
		ON coords2.npp = tree.npp
	WHERE
		tree.cube = 'M' AND coords2.DATEPOINT >= '1988-01-01'::date
	ORDER BY
		npp, a;", DT = TRUE)

nfi_data = na.omit(nfi_data)

codesessences = codesessences[essence_ifn < 100]
codesessences = codesessences[, nfi := as.character(essence_ifn)]
codesessences[essence_ifn < 10, nfi := paste0("0", nfi)]
codesessences[, speciesName_sci := paste(genre, espece)]

nfi_data = merge.data.table(nfi_data, codesessences[, .(nfi, genre, speciesName_sci)], by.x = "ess", by.y = "nfi")

ls_species = nfi_data[, .N, by = speciesName_sci]
setorder(ls_species, speciesName_sci)

disconnect_db(db)

nfi_data[, ess := NULL]

if (isTRUE(nfi_data[, all.equal(v, vtot, tol = 1e-5)]))
{
	print("It seems that v and vtot are the same, which is strange as I was expecting vtot = (1 - r)*v")
	nfi_data[, vtot := NULL]
	nfi_data[, r := NULL]
} else {
	stop("When I downloaded the data, v and vtot were the same. It seems it is not anymore! Check what could have happened")
}

setnames(nfi_data, new = c("plot_id", "tree_id", "circumference_m", "height", "merchantable_trunk_volume_m3",
	"x_lambert", "y_lambert", "genus", "speciesName_sci"))

nfi_data[, nb_indiv := .N, by = speciesName_sci]
```

### Coordinates

Unfortunately, not all the coordinates are available... And when they are, different work must be performed depending on the source:

1.  'protocole Oudin' INRA data: the coordinates are directly available, in the table `codesforets` that I already joined to `inra_arbres`.

2.  French NFI: I included the coordinates in my query.

3.  ONF: I asked directly Christine Deleuze (answer from the 09 January 2025). There is unfortunately no coordinates (at least, none that can be provided to me...).

#### Coordinates 'protocole Oudin' INRA data

```{r}
## Coordinates
coords_inra = unique(inra_arbres[, .(plot_id, lon, lat)])

coords_inra[, lon := as.character(lon)]
coords_inra[, lat := as.character(lat)]

coords_inra[, lon_dec := angle2dec(lon)]
coords_inra[, lat_dec := angle2dec(lat)]

coords_inra = terra::vect(x = coords_inra[, .(plot_id, lon_dec, lat_dec)],
	geom = c("lon_dec", "lat_dec"),
	crs = "EPSG:4326")
```

#### Coordinates French NFI

```{r}
## Coordinates
coords_nfi = unique(nfi_data[, .(plot_id, x_lambert, y_lambert)])

coords_nfi = terra::vect(x = coords_nfi[, .(plot_id, x_lambert, y_lambert)],
	geom = c("x_lambert", "y_lambert"), crs = "EPSG:27572") # Lambert zone II, I checked it is the used projection
```

### Gather all the datasets into a single one
Now that all the data are ready 

```{r}

```


### Compute the indices for Stan

Stan language uses vectors and arrays (think matrices), but does not know data.frames or data.tables. Therefore, it is necessary to provide an ordered dataset accordingly to the structure of the model. Here, we need to order by functional type and by species within function type. Then, the index table just indicates when each functional type and each species starts and ends in the data. This is not only necessary for Stan, but can also accelerate the computation by vectorising certain calculus. Of course, it is important that the data order is not changed **after** the index table is generated.
